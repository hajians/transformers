{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dde47a6-d4a9-425d-9285-7a3999b9665c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoConfig, AutoModel, DistilBertTokenizer\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers_tutorial.networks.attention_head import MultiHeadAttention, FeedForward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73685a7-f824-4384-8cd9-164ef62b5a7e",
   "metadata": {},
   "source": [
    "# Load data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fa0dc09-632c-4a89-804c-ed9358699ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poem_raw = pd.json_normalize(pd.read_json(\"../data/verse_202412132333.json\").iloc[:,0])\n",
    "\n",
    "def preprocess(df):\n",
    "    df_ = df.copy()\n",
    "    diacritics_pattern = r'[\\u064E\\u064F\\u0650\\u0651\\u0652\\u0640]'\n",
    "    \n",
    "    df_['text'] = df_['text'].apply(lambda x: re.sub(diacritics_pattern, '', x))\n",
    "    df_['verse_index'] = (df_['vorder']-1) // 2\n",
    "\n",
    "    df_output = (\n",
    "        df_.sort_values(\"position\", ascending=True)\n",
    "        .groupby([\"poem_id\", \"verse_index\"])[\"text\"]\n",
    "        .agg(lambda x: \" - \".join(x.tolist())\n",
    "            ).reset_index()\n",
    "    )\n",
    "    \n",
    "    # df_output['text_reverse'] = df_output['text'].apply(lambda x: \" \".join(reversed(x.strip().split(\" \"))))\n",
    "\n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7214b37-fc3b-45e7-90b0-5f96f3f0d6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = preprocess(df_poem_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7250f913-b003-4cfa-851d-1b42e4e71460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poem_id</th>\n",
       "      <th>vorder</th>\n",
       "      <th>position</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>700000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>همچو شاهین به هوا جلوه کنان می گذرم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>700000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>تیزرو  بالی و تازنده پری داده مرا</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   poem_id  vorder  position                                 text\n",
       "2   700000       3         0  همچو شاهین به هوا جلوه کنان می گذرم\n",
       "3   700000       4         1    تیزرو  بالی و تازنده پری داده مرا"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_poem_raw.iloc[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93f98755-9651-4fd3-857a-933ac658e2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['همچو شاهین به هوا جلوه کنان می گذرم - تیزرو  بالی و تازنده پری داده مرا'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep[['text']].iloc[1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03747ef7-9222-4854-8fad-ef68d7d0c3ab",
   "metadata": {},
   "source": [
    "# Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ffe1bf0-272d-4254-822e-97dedfbc5410",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mitra-mir/BERT-Persian-Poetry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5e09bac-fb90-491a-bfb6-f140ae82f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_inputs(df_):\n",
    "    return tokenizer(df_['text'].values.tolist(), padding=False)\n",
    "\n",
    "def decode_tokens(tokens_, skip_special_tokens=False):\n",
    "    decoded = tokenizer.batch_decode(tokens_, skip_special_tokens=skip_special_tokens)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d23b75ac-0083-4e2e-aa77-6164fe82b87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = encode_inputs(df_prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aebd93-f43a-419f-8545-7ac95e2afc27",
   "metadata": {},
   "source": [
    "Make sure that tokens orders are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16b557d3-8da9-43f8-a448-df80f8c6bc80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 2164, 1112, 10880, 1923],\n",
       " ['[CLS]',\n",
       "  'همچ',\n",
       "  '##و',\n",
       "  'شاهین',\n",
       "  'به',\n",
       "  'هوا',\n",
       "  'جلوه',\n",
       "  'کنان',\n",
       "  'می',\n",
       "  'گذر',\n",
       "  '##م',\n",
       "  '-',\n",
       "  'تیزر',\n",
       "  '##و',\n",
       "  'بالی',\n",
       "  'و',\n",
       "  'تاز',\n",
       "  '##نده',\n",
       "  'پری',\n",
       "  'داده'],\n",
       " ['[CLS] همچو شاهین به هوا جلوه کنان می گذرم - تیزرو بالی و تازنده پری داده مرا [SEP]'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['input_ids'][1][:5], decode_tokens(tokens['input_ids'][1][:20]), decode_tokens(tokens['input_ids'][1:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332dfc8e-903b-4612-b9de-e7f022a52a15",
   "metadata": {},
   "source": [
    "## Generate training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c42c62a6-1e35-4e7b-8410-f81a9fd5db98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequences(tokens_):\n",
    "    output = []\n",
    "    target = []\n",
    "    for seq in tokens_['input_ids']:\n",
    "        for ix in range(1, len(seq)):\n",
    "            output += [torch.tensor(seq[:ix])]\n",
    "            target.append(seq[ix])\n",
    "\n",
    "    padded_tensor = pad_sequence(output, batch_first=True, padding_value=0)\n",
    "    attention_mask_tensor = (padded_tensor != 0).int()\n",
    "          \n",
    "    return {\"input_ids\": padded_tensor, \"attention_mask\": attention_mask_tensor}, torch.tensor(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e1a8f49-72b4-4572-8f6e-982b1b4b883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tokens, targets = generate_sequences(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fefdce1-d664-4800-9317-1e60077d0f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([71097, 39])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_tokens['input_ids'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61204331-0f25-4435-92d4-be43ccc6baee",
   "metadata": {},
   "source": [
    "Check if target is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a86618ac-fa81-42d6-91eb-2572a3bf2a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['',\n",
       "  'خواب',\n",
       "  'خواب دیدم',\n",
       "  'خواب دیدم که',\n",
       "  'خواب دیدم که خدا',\n",
       "  'خواب دیدم که خدا بال',\n",
       "  'خواب دیدم که خدا بال و',\n",
       "  'خواب دیدم که خدا بال و پری',\n",
       "  'خواب دیدم که خدا بال و پری داده',\n",
       "  'خواب دیدم که خدا بال و پری داده مرا'],\n",
       " ['خواب',\n",
       "  'دیدم',\n",
       "  'که',\n",
       "  'خدا',\n",
       "  'بال',\n",
       "  'و',\n",
       "  'پری',\n",
       "  'داده',\n",
       "  'مرا',\n",
       "  '-',\n",
       "  'در',\n",
       "  'هوا',\n",
       "  'قوت',\n",
       "  'سیر',\n",
       "  'و',\n",
       "  'سفری',\n",
       "  'داده',\n",
       "  'مرا',\n",
       "  '',\n",
       "  'همچ'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_tokens(full_tokens['input_ids'][:10], skip_special_tokens=True), decode_tokens(targets[:20], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aeefcf95-83c7-4593-a941-bdeca60db854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_tokens['attention_mask'][:10,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cce264e-3176-4f48-9615-09fcb176199d",
   "metadata": {},
   "source": [
    "## Train / validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6d0cf6f-ab70-4a7b-b8bb-2562fcfe4ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FULL_DATASET = targets.shape[0]\n",
    "TRAIN_FRAC = 0.9\n",
    "TRAIN_SIZE = int(N_FULL_DATASET * TRAIN_FRAC)\n",
    "\n",
    "SEQ_LEN = full_tokens['input_ids'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "578a68a3-0519-421b-90c5-acbff9655887",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset.from_dict({key: val[:TRAIN_SIZE] for key, val in full_tokens.items()})\n",
    "\n",
    "#.add_column(\"target\", targets[:TRAIN_SIZE])\n",
    "train_target = targets[:TRAIN_SIZE]\n",
    "\n",
    "validation_data = Dataset.from_dict({key: val[TRAIN_SIZE:] for key, val in full_tokens.items()})\n",
    "validation_target = targets[TRAIN_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c45a886-2a04-4a40-a84d-2857e5f0d1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.set_format(\"pt\"), train_data.set_format(\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1edf4f4a-4b29-42cb-962b-3bed00337214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7110]), torch.Size([63987]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_targets.shape, train_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4fdaed-f61f-4ff1-92eb-71feaba17935",
   "metadata": {},
   "source": [
    "# Decoder Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2db8dab0-fccd-44c0-8a61-c61e05faa859",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoderLayer(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim, n_heads, intermediate_dim, device, p_dropout=0.2, seq_len=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        config = AutoConfig.from_pretrained(\"bert-base-uncased\")\n",
    "        config.vocab_size = vocab_size\n",
    "        if seq_len:\n",
    "            config.max_position_embeddings = seq_len\n",
    "            \n",
    "        self.embeddings = AutoModel.from_config(config).embeddings\n",
    "\n",
    "        \n",
    "        self.multi_head_attention = MultiHeadAttention(\n",
    "            emb_dim=config.hidden_size, hidden_dim=hidden_dim, n_heads=n_heads, is_decoder=True,\n",
    "        )\n",
    "        self.ff = FeedForward(\n",
    "            hidden_dim=hidden_dim,\n",
    "            intermediate_dim=intermediate_dim,\n",
    "            p_dropout=p_dropout,\n",
    "        )\n",
    "        self.layer_norm_1 = nn.LayerNorm(hidden_dim)\n",
    "        self.layer_norm_2 = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "\n",
    "    def forward(self, input_):\n",
    "        data = {\n",
    "            k: input_[k].to(self.device)\n",
    "            for k in input_.keys()\n",
    "            if k in [\"attention_mask\", \"input_ids\"]\n",
    "        }\n",
    "\n",
    "        x = self.embeddings(data['input_ids'])\n",
    "        \n",
    "        residual = x\n",
    "        \n",
    "        x = residual + self.multi_head_attention(x, data[\"attention_mask\"])\n",
    "        x = self.layer_norm_1(x)\n",
    "\n",
    "        residual = x\n",
    "        x = residual + self.ff(x)\n",
    "        x = self.layer_norm_2(x)\n",
    "        \n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "623be110-8d4b-4197-8d5e-3a4dcf238897",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea8d43fa-2fd8-479e-b4eb-bfdf32776115",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "HIDDEN_DIM = 1024\n",
    "INTERMEDIATE_DIM = HIDDEN_DIM * 4\n",
    "N_HEADS = 12\n",
    "\n",
    "trasnformer_decoder = TransformerDecoderLayer(\n",
    "    vocab_size=VOCAB_SIZE, \n",
    "    hidden_dim=HIDDEN_DIM, \n",
    "    n_heads=N_HEADS, \n",
    "    intermediate_dim=INTERMEDIATE_DIM,\n",
    "    seq_len=SEQ_LEN,\n",
    "    device=device,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e1985e3-1353-4936-82e2-c45e4b4d8a6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerDecoderLayer(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(42000, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(39, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (multi_head_attention): MultiHeadAttention(\n",
       "    (heads): ModuleList(\n",
       "      (0-11): 12 x AttentionHead(\n",
       "        (q): Linear(in_features=768, out_features=85, bias=True)\n",
       "        (k): Linear(in_features=768, out_features=85, bias=True)\n",
       "        (v): Linear(in_features=768, out_features=85, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (ff): FeedForward(\n",
       "    (layers): Sequential(\n",
       "      (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (linear): Linear(in_features=1024, out_features=42000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trasnformer_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "099dcbdb-4739-4928-99d0-8ca890ea631c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   2, 9669,    0,  ...,    0,    0,    0],\n",
       "         [   2, 9669, 1110,  ...,    0,    0,    0],\n",
       "         [   2, 9669, 1110,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   2, 2143,  607,  ...,    0,    0,    0],\n",
       "         [   2, 2143,  607,  ...,    0,    0,    0],\n",
       "         [   2, 2143,  607,  ...,    0,    0,    0]]),\n",
       " 'attention_mask': tensor([[1, 1, 0,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "585b8fd5-4fd7-465e-bd15-ca0933e10e69",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (78x1020 and 1024x1024)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtrasnformer_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/transformers-py311/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/transformers-py311/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[27], line 40\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[0;34m(self, input_)\u001b[0m\n\u001b[1;32m     36\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     38\u001b[0m residual \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m---> 40\u001b[0m x \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm_1(x)\n\u001b[1;32m     43\u001b[0m residual \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/transformers-py311/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/transformers-py311/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/repos/transformers/transformers_tutorial/networks/attention_head.py:79\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, hidden_state, attention_masks)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_state, attention_masks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     76\u001b[0m     output_att \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m     77\u001b[0m         [head(hidden_state, attention_masks) \u001b[38;5;28;01mfor\u001b[39;00m head \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     78\u001b[0m     )\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_att\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/transformers-py311/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/transformers-py311/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/transformers-py311/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (78x1020 and 1024x1024)"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    trasnformer_decoder(validation_data[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839a8d13-fce2-45ed-a199-b42b40ee6413",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913e62b3-a51b-4864-87fa-9d71d356bf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in trasnformer_decoder.named_parameters():\n",
    "    if i[1].requires_grad:\n",
    "        print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85464217-cc99-412f-953b-5150a2dfeb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    params={p for p in trasnformer_decoder.parameters() if p.requires_grad}, \n",
    "    lr=1e-5, weight_decay=0.01\n",
    ")\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "trainer = Trainer(optimizer=optimizer, loss=loss_fn, model=transf_clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers-py311",
   "language": "python",
   "name": "transformers-py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
